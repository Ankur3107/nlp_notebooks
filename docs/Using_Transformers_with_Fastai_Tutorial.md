# Package Installation


```
!git clone https://github.com/devkosal/fastai_roberta.git
```

    Cloning into 'fastai_roberta'...
    remote: Enumerating objects: 171, done.[K
    remote: Counting objects: 100% (171/171), done.[K
    remote: Compressing objects: 100% (121/121), done.[K
    remote: Total 171 (delta 91), reused 111 (delta 44), pack-reused 0[K
    Receiving objects: 100% (171/171), 25.46 MiB | 18.58 MiB/s, done.
    Resolving deltas: 100% (91/91), done.



```
!pip install fastai==1.0.60 transformers==2.3.0
```

    Collecting fastai==1.0.60
    [?25l  Downloading https://files.pythonhosted.org/packages/f5/e4/a7025bf28f303dbda0f862c09a7f957476fa92c9271643b4061a81bb595f/fastai-1.0.60-py3-none-any.whl (237kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 4.7MB/s 
    [?25hCollecting transformers==2.3.0
    [?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450kB 7.4MB/s 
    [?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (3.2.2)
    Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.3.2)
    Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.18.5)
    Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (7.0.0)
    Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (7.352.0)
    Requirement already satisfied: dataclasses; python_version < "3.7" in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (0.7)
    Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (2.23.0)
    Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (3.13)
    Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (2.7.1)
    Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.0.0)
    Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (20.4)
    Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (0.7.0+cu101)
    Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (4.6.3)
    Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (2.2.4)
    Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.6.0+cu101)
    Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.4.1)
    Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==1.0.60) (1.0.5)
    Collecting sentencepiece
    [?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 7.0MB/s 
    [?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (1.14.48)
    Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (4.41.1)
    Collecting sacremoses
    [?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 26.1MB/s 
    [?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0) (2019.12.20)
    Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.60) (2.4.7)
    Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.60) (2.8.1)
    Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.60) (0.10.0)
    Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==1.0.60) (1.2.0)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.60) (1.24.3)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.60) (2020.6.20)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.60) (3.0.4)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai==1.0.60) (2.10)
    Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai==1.0.60) (1.15.0)
    Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (1.0.2)
    Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (0.7.1)
    Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (0.4.1)
    Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (1.1.3)
    Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (3.0.2)
    Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (1.0.0)
    Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (49.6.0)
    Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (2.0.3)
    Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (7.4.0)
    Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18->fastai==1.0.60) (1.0.2)
    Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai==1.0.60) (0.16.0)
    Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai==1.0.60) (2018.9)
    Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.10.0)
    Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (0.3.3)
    Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.3.0) (1.17.48)
    Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)
    Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0) (0.16.0)
    Requirement already satisfied: importlib-metadata>=0.20; python_version < "3.8" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.60) (1.7.0)
    Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->transformers==2.3.0) (0.15.2)
    Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < "3.8"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->fastai==1.0.60) (3.1.0)
    Building wheels for collected packages: sacremoses
      Building wheel for sacremoses (setup.py) ... [?25l[?25hdone
      Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=aef96c81bb474827b2b34caa9690e68458a664de90731bcc580754ce52b74dd7
      Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45
    Successfully built sacremoses
    Installing collected packages: fastai, sentencepiece, sacremoses, transformers
      Found existing installation: fastai 1.0.61
        Uninstalling fastai-1.0.61:
          Successfully uninstalled fastai-1.0.61
    Successfully installed fastai-1.0.60 sacremoses-0.0.43 sentencepiece-0.1.91 transformers-2.3.0


# Load And Set Configuration


```
from fastai.text import *
from fastai.metrics import *
from transformers import RobertaTokenizer
```


```
# Creating a config object to store task specific information
class Config(dict):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        for k, v in kwargs.items():
            setattr(self, k, v)
    
    def set(self, key, val):
        self[key] = val
        setattr(self, key, val)
        
config = Config(
    testing=True,
    seed = 2019,
    roberta_model_name='roberta-base', # can also be exchnaged with roberta-large 
    max_lr=1e-5,
    epochs=1,
    use_fp16=False,
    bs=4, 
    max_seq_len=256, 
    num_labels = 2,
    hidden_dropout_prob=.05,
    hidden_size=768, # 1024 for roberta-large
    start_tok = "<s>",
    end_tok = "</s>",
)
```


```
df = pd.read_csv("fastai_roberta/fastai_roberta_imdb/imdb_dataset.csv")
```


```
if config.testing: df = df[:5000]
print(df.shape)
```

    (5000, 2)



```
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>One of the other reviewers has mentioned that ...</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>2</th>
      <td>I thought this was a wonderful way to spend ti...</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Basically there's a family where a little boy ...</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Petter Mattei's "Love in the Time of Money" is...</td>
      <td>positive</td>
    </tr>
  </tbody>
</table>
</div>




```
feat_cols = "review"
label_cols = "sentiment"
```

# Setting Up the Tokenizer


```
class FastAiRobertaTokenizer(BaseTokenizer):
    """Wrapper around RobertaTokenizer to be compatible with fastai"""
    def __init__(self, tokenizer: RobertaTokenizer, max_seq_len: int=128, **kwargs): 
        self._pretrained_tokenizer = tokenizer
        self.max_seq_len = max_seq_len 
    def __call__(self, *args, **kwargs): 
        return self 
    def tokenizer(self, t:str) -> List[str]: 
        """Adds Roberta bos and eos tokens and limits the maximum sequence length""" 
        return [config.start_tok] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [config.end_tok]
```


```
# create fastai tokenizer for roberta
roberta_tok = RobertaTokenizer.from_pretrained("roberta-base")

fastai_tokenizer = Tokenizer(tok_func=FastAiRobertaTokenizer(roberta_tok, max_seq_len=config.max_seq_len), 
                             pre_rules=[], post_rules=[])
```


```
# create fastai vocabulary for roberta
path = Path()
roberta_tok.save_vocabulary(path)

with open('vocab.json', 'r') as f:
    roberta_vocab_dict = json.load(f)
    
fastai_roberta_vocab = Vocab(list(roberta_vocab_dict.keys()))
```


```
# Setting up pre-processors
class RobertaTokenizeProcessor(TokenizeProcessor):
    def __init__(self, tokenizer):
         super().__init__(tokenizer=tokenizer, include_bos=False, include_eos=False)

class RobertaNumericalizeProcessor(NumericalizeProcessor):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)


def get_roberta_processor(tokenizer:Tokenizer=None, vocab:Vocab=None):
    """
    Constructing preprocessors for Roberta
    We remove sos and eos tokens since we add that ourselves in the tokenizer.
    We also use a custom vocabulary to match the numericalization with the original Roberta model.
    """
    return [RobertaTokenizeProcessor(tokenizer=tokenizer), RobertaNumericalizeProcessor(vocab=vocab)]
```

# Setting up the DataBunch


```
# Creating a Roberta specific DataBunch class
class RobertaDataBunch(TextDataBunch):
    "Create a `TextDataBunch` suitable for training Roberta"
    @classmethod
    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=64, val_bs:int=None, pad_idx=1,
               pad_first=True, device:torch.device=None, no_check:bool=False, backwards:bool=False, 
               dl_tfms:Optional[Collection[Callable]]=None, **dl_kwargs) -> DataBunch:
        "Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`"
        datasets = cls._init_ds(train_ds, valid_ds, test_ds)
        val_bs = ifnone(val_bs, bs)
        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)
        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs)
        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)
        dataloaders = [train_dl]
        for ds in datasets[1:]:
            lengths = [len(t) for t in ds.x.items]
            sampler = SortSampler(ds.x, key=lengths.__getitem__)
            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))
        return cls(*dataloaders, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)
```


```
class RobertaTextList(TextList):
    _bunch = RobertaDataBunch
    _label_cls = TextList
```


```
# loading the tokenizer and vocab processors
processor = get_roberta_processor(tokenizer=fastai_tokenizer, vocab=fastai_roberta_vocab)
```


```
# creating our databunch 
data = RobertaTextList.from_df(df, ".", cols=feat_cols, processor=processor) \
    .split_by_rand_pct(seed=config.seed) \
    .label_from_df(cols=label_cols,label_cls=CategoryList) \
    .databunch(bs=config.bs, pad_first=False, pad_idx=0)
```










```
data
```




    RobertaDataBunch;
    
    Train: LabelList (4000 items)
    x: RobertaTextList
    <s> One Ä of Ä the Ä other Ä reviewers Ä has Ä mentioned Ä that Ä after Ä watching Ä just Ä 1 Ä Oz Ä episode Ä you 'll Ä be Ä hooked . Ä They Ä are Ä right , Ä as Ä this Ä is Ä exactly Ä what Ä happened Ä with Ä me .< br Ä / >< br Ä /> The Ä first Ä thing Ä that Ä struck Ä me Ä about Ä Oz Ä was Ä its Ä brutality Ä and Ä unfl inch ing Ä scenes Ä of Ä violence , Ä which Ä set Ä in Ä right Ä from Ä the Ä word Ä GO . Ä Trust Ä me , Ä this Ä is Ä not Ä a Ä show Ä for Ä the Ä faint Ä heart ed Ä or Ä timid . Ä This Ä show Ä pulls Ä no Ä punches Ä with Ä regards Ä to Ä drugs , Ä sex Ä or Ä violence . Ä Its Ä is Ä hardcore , Ä in Ä the Ä classic Ä use Ä of Ä the Ä word .< br Ä / >< br Ä /> It Ä is Ä called Ä O Z Ä as Ä that Ä is Ä the Ä nickname Ä given Ä to Ä the Ä Oswald Ä Maximum Ä Security Ä State Ä Pen itent ary . Ä It Ä focuses Ä mainly Ä on Ä Emerald Ä City , Ä an Ä experimental Ä section Ä of Ä the Ä prison Ä where Ä all Ä the Ä cells Ä have Ä glass Ä fronts Ä and Ä face Ä in wards , Ä so Ä privacy Ä is Ä not Ä high Ä on Ä the Ä agenda . Ä Em Ä City Ä is Ä home Ä to Ä many .. A ry ans , Ä Muslims , Ä gang st as , Ä Latinos , Ä Christians , Ä Italians , Ä Irish Ä and Ä more .... so Ä sc uff les , Ä death Ä stares , Ä dod gy Ä dealings Ä and Ä shady Ä agreements Ä are Ä never Ä far Ä away .< br Ä / >< br Ä /> I Ä would Ä say Ä the Ä main Ä appeal Ä of Ä the Ä show Ä is Ä due Ä to Ä the Ä fact Ä that Ä it Ä goes Ä where Ä other Ä shows Ä wouldn 't Ä dare . Ä Forget Ä pretty Ä pictures Ä painted Ä for Ä mainstream Ä audiences , Ä forget Ä charm , Ä forget </s>,<s> A Ä wonderful Ä little Ä production . Ä < br Ä / >< br Ä /> The Ä filming Ä technique Ä is Ä very Ä un assuming - Ä very Ä old - time - BBC Ä fashion Ä and Ä gives Ä a Ä comforting , Ä and Ä sometimes Ä discomfort ing , Ä sense Ä of Ä realism Ä to Ä the Ä entire Ä piece . Ä < br Ä / >< br Ä /> The Ä actors Ä are Ä extremely Ä well Ä chosen - Ä Michael Ä Sheen Ä not Ä only Ä " has Ä got Ä all Ä the Ä pol ari " Ä but Ä he Ä has Ä all Ä the Ä voices Ä down Ä pat Ä too ! Ä You Ä can Ä truly Ä see Ä the Ä seamless Ä editing Ä guided Ä by Ä the Ä references Ä to Ä Williams ' Ä diary Ä entries , Ä not Ä only Ä is Ä it Ä well Ä worth Ä the Ä watching Ä but Ä it Ä is Ä a Ä terrific ly Ä written Ä and Ä performed Ä piece . Ä A Ä master ful Ä production Ä about Ä one Ä of Ä the Ä great Ä master 's Ä of Ä comedy Ä and Ä his Ä life . Ä < br Ä / >< br Ä /> The Ä realism Ä really Ä comes Ä home Ä with Ä the Ä little Ä things : Ä the Ä fantasy Ä of Ä the Ä guard Ä which , Ä rather Ä than Ä use Ä the Ä traditional Ä ' dream ' Ä techniques Ä remains Ä solid Ä then Ä disappears . Ä It Ä plays Ä on Ä our Ä knowledge Ä and Ä our Ä senses , Ä particularly Ä with Ä the Ä scenes Ä concerning Ä Or ton Ä and Ä Hall i well Ä and Ä the Ä sets Ä ( particularly Ä of Ä their Ä flat Ä with Ä Hall i well 's Ä mur als Ä decor ating Ä every Ä surface ) Ä are Ä terribly Ä well Ä done . </s>,<s> Basically Ä there 's Ä a Ä family Ä where Ä a Ä little Ä boy Ä ( Jake ) Ä thinks Ä there 's Ä a Ä zombie Ä in Ä his Ä closet Ä & Ä his Ä parents Ä are Ä fighting Ä all Ä the Ä time .< br Ä / >< br Ä /> This Ä movie Ä is Ä slower Ä than Ä a Ä soap Ä opera ... Ä and Ä suddenly , Ä Jake Ä decides Ä to Ä become Ä Ram bo Ä and Ä kill Ä the Ä zombie .< br Ä / >< br Ä /> OK , Ä first Ä of Ä all Ä when Ä you 're Ä going Ä to Ä make Ä a Ä film Ä you Ä must Ä Dec ide Ä if Ä its Ä a Ä thriller Ä or Ä a Ä drama ! Ä As Ä a Ä drama Ä the Ä movie Ä is Ä watch able . Ä Parents Ä are Ä divor cing Ä & Ä arguing Ä like Ä in Ä real Ä life . Ä And Ä then Ä we Ä have Ä Jake Ä with Ä his Ä closet Ä which Ä totally Ä ruins Ä all Ä the Ä film ! Ä I Ä expected Ä to Ä see Ä a Ä B OO GE Y MAN Ä similar Ä movie , Ä and Ä instead Ä i Ä watched Ä a Ä drama Ä with Ä some Ä meaningless Ä thriller Ä spots .< br Ä / >< br Ä /> 3 Ä out Ä of Ä 10 Ä just Ä for Ä the Ä well Ä playing Ä parents Ä & Ä descent Ä dialog s . Ä As Ä for Ä the Ä shots Ä with Ä Jake : Ä just Ä ignore Ä them . </s>,<s> Pet ter Ä Matte i 's Ä " Love Ä in Ä the Ä Time Ä of Ä Money " Ä is Ä a Ä visually Ä stunning Ä film Ä to Ä watch . Ä Mr . Ä Matte i Ä offers Ä us Ä a Ä vivid Ä portrait Ä about Ä human Ä relations . Ä This Ä is Ä a Ä movie Ä that Ä seems Ä to Ä be Ä telling Ä us Ä what Ä money , Ä power Ä and Ä success Ä do Ä to Ä people Ä in Ä the Ä different Ä situations Ä we Ä encounter . Ä < br Ä / >< br Ä /> This Ä being Ä a Ä variation Ä on Ä the Ä Arthur Ä Schn itz ler 's Ä play Ä about Ä the Ä same Ä theme , Ä the Ä director Ä transfers Ä the Ä action Ä to Ä the Ä present Ä time Ä New Ä York Ä where Ä all Ä these Ä different Ä characters Ä meet Ä and Ä connect . Ä Each Ä one Ä is Ä connected Ä in Ä one Ä way , Ä or Ä another Ä to Ä the Ä next Ä person , Ä but Ä no Ä one Ä seems Ä to Ä know Ä the Ä previous Ä point Ä of Ä contact . Ä Sty lish ly , Ä the Ä film Ä has Ä a Ä sophisticated Ä luxurious Ä look . Ä We Ä are Ä taken Ä to Ä see Ä how Ä these Ä people Ä live Ä and Ä the Ä world Ä they Ä live Ä in Ä their Ä own Ä habitat .< br Ä / >< br Ä /> The Ä only Ä thing Ä one Ä gets Ä out Ä of Ä all Ä these Ä souls Ä in Ä the Ä picture Ä is Ä the Ä different Ä stages Ä of Ä loneliness Ä each Ä one Ä inhab its . Ä A Ä big Ä city Ä is Ä not Ä exactly Ä the Ä best Ä place Ä in Ä which Ä human Ä relations Ä find Ä sincere Ä fulfillment , Ä as Ä one Ä discern s Ä is Ä the Ä case Ä with Ä most Ä of Ä the Ä people Ä we Ä encounter .< br Ä / >< br Ä /> The Ä acting Ä is Ä good Ä under Ä Mr . Ä Matte i 's Ä direction . Ä Steve Ä Bus ce mi , Ä Ros ario Ä Dawson , Ä Carol Ä Kane , Ä Michael Ä Imper iol </s>,<s> Probably Ä my Ä all - time Ä favorite Ä movie , Ä a Ä story Ä of Ä self lessness , Ä sacrifice Ä and Ä dedication Ä to Ä a Ä noble Ä cause , Ä but Ä it 's Ä not Ä preach y Ä or Ä boring . Ä It Ä just Ä never Ä gets Ä old , Ä despite Ä my Ä having Ä seen Ä it Ä some Ä 15 Ä or Ä more Ä times Ä in Ä the Ä last Ä 25 Ä years . Ä Paul Ä Luk as ' Ä performance Ä brings Ä tears Ä to Ä my Ä eyes , Ä and Ä Bet te Ä Davis , Ä in Ä one Ä of Ä her Ä very Ä few Ä truly Ä sympathetic Ä roles , Ä is Ä a Ä delight . Ä The Ä kids Ä are , Ä as Ä grandma Ä says , Ä more Ä like Ä " d ressed - up Ä mid gets " Ä than Ä children , Ä but Ä that Ä only Ä makes Ä them Ä more Ä fun Ä to Ä watch . Ä And Ä the Ä mother 's Ä slow Ä awakening Ä to Ä what 's Ä happening Ä in Ä the Ä world Ä and Ä under Ä her Ä own Ä roof Ä is Ä believable Ä and Ä startling . Ä If Ä I Ä had Ä a Ä dozen Ä thumbs , Ä they 'd Ä all Ä be Ä " up " Ä for Ä this Ä movie . </s>
    y: CategoryList
    positive,positive,negative,positive,positive
    Path: .;
    
    Valid: LabelList (1000 items)
    x: RobertaTextList
    <s> Apparently , Ä The Ä Mut ilation Ä Man Ä is Ä about Ä a Ä guy Ä who Ä wand ers Ä the Ä land Ä performing Ä shows Ä of Ä self - mut ilation Ä as Ä a Ä way Ä of Ä coping Ä with Ä his Ä abusive Ä childhood . Ä I Ä use Ä the Ä word Ä ' app arently ' Ä because Ä without Ä listening Ä to Ä a Ä director Ä Andy Ä Co pp 's Ä commentary Ä ( which Ä I Ä didn 't Ä have Ä available Ä to Ä me ) Ä or Ä reading Ä up Ä on Ä the Ä film Ä prior Ä to Ä watching , Ä viewers Ä won 't Ä have Ä a Ä clue Ä what Ä it Ä is Ä about .< br Ä / >< br Ä /> G ore h ounds Ä and Ä fans Ä of Ä extreme Ä movies Ä may Ä be Ä lured Ä into Ä watching Ä The Ä Mut ilation Ä Man Ä with Ä the Ä promise Ä of Ä some Ä harsh Ä scenes Ä of Ä spl atter Ä and Ä unsettling Ä real - life Ä footage , Ä but Ä unless Ä they 're Ä also Ä fond Ä of Ä pret entious , Ä headache - inducing , Ä experimental Ä art - house Ä cinema , Ä they 'll Ä find Ä this Ä one Ä a Ä real Ä chore Ä to Ä sit Ä through .< br Ä / >< br Ä /> 82 Ä minutes Ä of Ä ugly Ä imagery Ä accompanied Ä by Ä dis - ch ord ant Ä sound , Ä terrible Ä music Ä and Ä incomprehensible Ä dialogue , Ä this Ä mind - n umb ingly Ä awful Ä dri vel Ä is Ä the Ä perfect Ä way Ä to Ä test Ä one 's Ä sanity : Ä if Ä you 've Ä still Ä got Ä all Ä your Ä mar bles , Ä you 'll Ä switch Ä this Ä rubbish Ä off Ä and Ä watch Ä something Ä decent Ä instead Ä ( I Ä watched Ä the Ä whole Ä thing , Ä but Ä am Ä well Ä aware Ä that Ä I 'm Ä completely Ä barking !). </s>,<s> Peter Ä C ushing Ä and Ä Donald Ä Ple as ance Ä are Ä legendary Ä actors , Ä and Ä director Ä K ost as Ä Kar ag ian nis Ä was Ä the Ä man Ä behind Ä the Ä successful Ä Greek Ä Gi allo - es quire Ä thriller Ä Death Ä Kiss Ä in Ä 1974 ; Ä and Ä yet Ä when Ä you Ä combine Ä the Ä three Ä talents , Ä all Ä you Ä get Ä is Ä this Ä complete Ä load Ä of Ä dri vel ! Ä God Ä only Ä knows Ä what Ä drove Ä the Ä likes Ä of Ä Peter Ä C ushing Ä and Ä Donald Ä Ple as ance Ä to Ä star Ä in Ä this Ä cheap ie Ä devil Ä worship Ä flick , Ä but Ä I Ä really Ä do Ä hope Ä they Ä were Ä well Ä paid Ä as Ä neither Ä one Ä deserves Ä something Ä as Ä amateur ish Ä as Ä this Ä on Ä their Ä resumes . Ä The Ä story Ä focuses Ä on Ä a Ä group Ä of Ä devil Ä worsh ippers Ä that Ä kidnap Ä some Ä kids , Ä leading Ä another Ä group Ä to Ä go Ä after Ä them . Ä The Ä pace Ä of Ä the Ä plot Ä is Ä very Ä slow Ä and Ä this Ä ensures Ä that Ä the Ä film Ä is Ä very Ä boring . Ä The Ä plot Ä is Ä also Ä a Ä long Ä way Ä from Ä being Ä original Ä and Ä anyone Ä with Ä even Ä a Ä passing Ä interest Ä in Ä the Ä horror Ä genre Ä will Ä have Ä seen Ä something Ä a Ä bit Ä like Ä this , Ä and Ä no Ä doubt Ä done Ä much Ä better . Ä The Ä obvious Ä lack Ä of Ä budget Ä is Ä felt Ä throughout Ä and Ä the Ä film Ä doesn 't Ä manage Ä to Ä overcome Ä this Ä at Ä any Ä point . Ä This Ä really Ä is Ä a Ä depressing Ä and Ä miserable Ä watch Ä and Ä not Ä even Ä a Ä slightly Ä decent Ä ending Ä manages Ä to Ä up Ä the Ä ante Ä enough Ä to Ä lift Ä this Ä film Ä out Ä of Ä the Ä very Ä bottom Ä of Ä the Ä barrel . Ä Extreme ly Ä poor Ä stuff Ä and Ä definitely Ä not Ä recommended ! </s>,<s> Back Ä in Ä the Ä 1970 s , Ä WP IX Ä ran Ä " The Ä Adventures Ä of Ä Superman " Ä every Ä weekday Ä afternoon Ä for Ä quite Ä a Ä few Ä years . Ä Every Ä once Ä in Ä a Ä while , Ä we 'd Ä get Ä a Ä treat Ä when Ä they Ä would Ä preempt Ä neighboring Ä shows Ä to Ä air Ä " Super man Ä and Ä the Ä Mole Ä Men ." Ä I Ä always Ä looked Ä forward Ä to Ä those Ä days . Ä Watching Ä it Ä recently , Ä I Ä was Ä surprised Ä at Ä just Ä how Ä bad Ä it Ä really Ä was .< br Ä / >< br Ä /> It Ä wasn 't Ä bad Ä because Ä of Ä the Ä special Ä effects , Ä or Ä lack Ä thereof . Ä True , Ä George Ä Reeves ' Ä Superman Ä costume Ä was Ä pretty Ä bad , Ä the Ä edges Ä of Ä the Ä foam Ä padding Ä used Ä to Ä make Ä him Ä look Ä more Ä imposing Ä being Ä plainly Ä visible . Ä And Ä true , Ä the Ä Mole Ä Men 's Ä costumes Ä were Ä even Ä worse . Ä What Ä was Ä supposed Ä to Ä be Ä a Ä furry Ä covering Ä wouldn 't Ä have Ä fooled Ä a Ä ten Ä year - old , Ä since Ä the Ä z ippers , Ä sleeve Ä he ms Ä and Ä badly Ä p illing Ä fabric Ä badly Ä tailored Ä into Ä bag gy Ä costumes Ä were Ä all Ä painfully Ä obvious . Ä But Ä these Ä were Ä forg ivable Ä shortcomings .< br Ä / >< br Ä /> No , Ä what Ä made Ä it Ä bad Ä were Ä the Ä cont rived Ä plot Ä devices . Ä Time Ä and Ä again , Ä Superman Ä failed Ä to Ä do Ä anything Ä to Ä keep Ä the Ä situation Ä from Ä deteriorating . Ä A Ä lyn ch Ä mob Ä is Ä searching Ä for Ä the Ä creatures ? Ä Rather Ä than Ä round Ä up Ä the Ä hysterical Ä crowd Ä or Ä search Ä for Ä the Ä creatures Ä himself , Ä he Ä stands Ä around Ä explaining Ä the Ä dangers Ä of Ä the Ä situation Ä to Ä Lois Ä and Ä the Ä PR </s>,<s> Sat an 's Ä Little Ä Hel per Ä is Ä one Ä of Ä the Ä better Ä B Ä Horror Ä movies Ä I Ä have Ä seen . Ä When Ä I Ä say Ä better Ä I Ä mean Ä the Ä story . Ä The Ä film Ä hat ches Ä a Ä new Ä plot , Ä something Ä that 's Ä not Ä so Ä clichÃƒÂ© Ä in Ä the Ä Horror Ä genre Ä - Ä something Ä fresh . Ä But Ä there Ä are Ä also Ä some Ä ridiculous Ä questions Ä that Ä come Ä along Ä with Ä it . Ä Questions Ä you Ä will Ä be Ä asking Ä yourself Ä throughout Ä the Ä movie .< br Ä / >< br Ä /> The Ä film Ä first Ä caught Ä my Ä attention Ä while Ä I Ä was Ä cruising Ä the Ä Horror Ä section Ä in Ä HM V . Ä I Ä was Ä tired Ä of Ä all Ä the Ä so Ä called Ä " ter r ifi ying " Ä Hollywood Ä block busters Ä and Ä wanted Ä something Ä different . Ä The Ä cover Ä art Ä for Ä Satan 's Ä Little Ä Hel per Ä immediately Ä caught Ä my Ä attention . Ä As Ä you Ä can Ä see , Ä the Ä image Ä draws Ä you Ä in Ä - Ä it 's Ä chilling ! Ä I Ä knew Ä it Ä was Ä a Ä straight Ä to Ä DVD Ä release Ä - Ä but Ä I Ä took Ä a Ä chance . Ä I Ä mean , Ä I Ä just Ä seen Ä " Boo gey Ä Man " Ä the Ä night Ä before Ä - Ä so Ä It Ä couldn 't Ä get Ä any Ä worse ! Ä After Ä I Ä watched Ä the Ä movie , Ä I Ä was Ä semi - s atisf ied . Ä I Ä loved Ä the Ä plot Ä of Ä the Ä movie . Ä It Ä was Ä really Ä creepy Ä how Ä the Ä killer Ä was Ä pretending Ä to Ä be Ä the Ä little Ä boys Ä friend , Ä so Ä he Ä could Ä kill . Ä In Ä some Ä sick Ä der anged Ä way , Ä he Ä actually Ä thought Ä he Ä and Ä the Ä little Ä boy Ä would Ä become Ä partners Ä - Ä a Ä duo Ä of Ä terror . Ä It Ä was Ä a </s>,<s> I Ä saw Ä this Ä gem Ä of Ä a Ä film Ä at Ä Cannes Ä where Ä it Ä was Ä part Ä of Ä the Ä directors Ä fortnight .< br Ä / >< br Ä /> Welcome Ä to Ä Coll in wood Ä is Ä nothing Ä short Ä of Ä superb . Ä Great Ä fun Ä throughout , Ä with Ä all Ä members Ä of Ä a Ä strong Ä cast Ä acting Ä their Ä socks Ä off . Ä It 's Ä a Ä sometimes Ä laugh Ä out Ä loud Ä comedy Ä about Ä a Ä petty Ä cro ok Ä ( Cos imo , Ä played Ä by Ä Luis Ä Gu zman ) Ä who Ä gets Ä caught Ä trying Ä to Ä steal Ä a Ä car Ä and Ä sent Ä to Ä prison . Ä While Ä in Ä prison Ä he Ä meets Ä a Ä ` l ifer ' Ä who Ä tells Ä him Ä of Ä ` the Ä ultimate Ä bell ini ' Ä Ã‚ Ä¸ Ä which Ä to Ä you Ä and Ä me Ä Ã‚ Ä¸ Ä is Ä a Ä sure - fire Ä get Ä rich Ä quick Ä scheme . Ä It Ä turns Ä out Ä that Ä there Ä is Ä a Ä way Ä through Ä from Ä a Ä deserted Ä building Ä into Ä the Ä towns Ä jew ell ers Ä shop Ä Ã‚ Ä¸ Ä which Ä could Ä net Ä millions . Ä Sounds Ä simple ? Ä Ã‚ Ä¸ Ä well Ä throw Ä in Ä all Ä kinds Ä of Ä w acky Ä characters Ä and Ä incidents Ä along Ä the Ä way Ä and Ä you Ä have Ä got Ä the Ä ingredients Ä for Ä a Ä one Ä wild Ä ride !! Ä Ã‚ Ä¸ Ä word Ä passes Ä from Ä one Ä low Ä life Ä loser Ä to Ä the Ä next Ä and Ä soon Ä a Ä team Ä of Ä them Ä are Ä assembled Ä to Ä try Ä and Ä cash Ä in Ä on Ä Cos im os Ä ` bell ini ' Ä lead Ä by Ä failed Ä boxer Ä Per o Ä ( Super bly Ä played Ä by Ä Sam Ä Rock well Ä Ã‚ Ä¸ Ä surely Ä a Ä star Ä in Ä the Ä making ) Ä and Ä reluctant Ä cro ok Ä Riley Ä ( William Ä H . Ä Macy ) Ä who Ä is Ä forced Ä to </s>
    y: CategoryList
    negative,negative,negative,negative,positive
    Path: .;
    
    Test: None



# Building the Model


```
import torch
import torch.nn as nn
from transformers import RobertaModel

# defining our model architecture 
class CustomRobertaModel(nn.Module):
    def __init__(self,num_labels=2):
        super(CustomRobertaModel,self).__init__()
        self.num_labels = num_labels
        self.roberta = RobertaModel.from_pretrained(config.roberta_model_name)
        self.dropout = nn.Dropout(config.hidden_dropout_prob)
        self.classifier = nn.Linear(config.hidden_size, num_labels) # defining final output layer
        
    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):
        _ , pooled_output = self.roberta(input_ids, token_type_ids, attention_mask) # 
        logits = self.classifier(pooled_output)        
        return logits
```


```
roberta_model = CustomRobertaModel(num_labels=config.num_labels)

learn = Learner(data, roberta_model, metrics=[accuracy])
```


```
learn.model.roberta.train() # setting roberta to train as it is in eval mode by default
learn.fit_one_cycle(config.epochs, max_lr=config.max_lr)
```


<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.184614</td>
      <td>0.180552</td>
      <td>0.929000</td>
      <td>02:17</td>
    </tr>
  </tbody>
</table>


# Getting Predictions


```
def get_preds_as_nparray(ds_type) -> np.ndarray:
    learn.model.roberta.eval()
    preds = learn.get_preds(ds_type)[0].detach().cpu().numpy()
    sampler = [i for i in data.dl(ds_type).sampler]
    reverse_sampler = np.argsort(sampler)
    ordered_preds = preds[reverse_sampler, :]
    pred_values = np.argmax(ordered_preds, axis=1)
    return ordered_preds, pred_values
```


```
preds, pred_values = get_preds_as_nparray(DatasetType.Valid)
```






```
# accuracy on valid
(pred_values == data.valid_ds.y.items).mean()
```




    0.929



# Saving/Loading the model weights


```
def save_model(learner, file_name):
    st = learner.model.state_dict()
    torch.save(st, file_name) # will save model in current dir # backend is pickle 

def load_model(learner, file_name):
    st = torch.load(file_name)
    learner.model.load_state_dict(st)
```


```
# monkey patching Learner methods to save and load model file
Learner.save_model = save_model
Learner.load_model = load_model
```


```
learn.save_model("my_model.bin")
learn.load_model("my_model.bin")
```
